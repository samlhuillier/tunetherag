{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git@main\n",
      "  Cloning https://github.com/huggingface/transformers.git (to revision main) to /var/tmp/pip-req-build-ho1h2goa\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /var/tmp/pip-req-build-ho1h2goa\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit e3a4bd2bee212a2d0fd9f03b27fe7bfc1debe42d\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bitsandbytes\n",
      "  Obtaining dependency information for bitsandbytes from https://files.pythonhosted.org/packages/1e/2c/af22cd797fc368a9f098ed03015730e6568b884fe67f9940793d944a4b7b/bitsandbytes-0.41.1-py3-none-any.whl.metadata\n",
      "  Downloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (3.12.2)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers==4.34.0.dev0)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.15.1 from https://files.pythonhosted.org/packages/72/21/51cddb8850ed3f4dbc21e57c3dabc49e64d5577857ddda7b2eb0ffc2ec0e/huggingface_hub-0.17.2-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.17.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.34.0.dev0)\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/d1/df/460ca6171a8494fcf37af43f52f6fac23e38784bb4a26563f6fa01ef6faf/regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (2.31.0)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers==4.34.0.dev0)\n",
      "  Obtaining dependency information for tokenizers<0.15,>=0.14 from https://files.pythonhosted.org/packages/57/bd/45b5ef6b088880779f70acf60027f7043ca5fa1b98f4a4345cf3aea09044/tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers==4.34.0.dev0)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/6c/f0/c17bbdb1e5f9dab29d44cade445135789f75f8f08ea2728d04493ea8412b/safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.34.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.34.0.dev0) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.34.0.dev0) (4.7.1)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers==4.34.0.dev0)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.15.1 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.34.0.dev0) (2023.7.22)\n",
      "Using cached bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
      "Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.9/771.9 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.34.0.dev0-py3-none-any.whl size=7700860 sha256=935dc18da6f02e6b1033654715582cf03c484b667ba2b37c80b6cfa8158f4c07\n",
      "  Stored in directory: /var/tmp/pip-ephem-wheel-cache-c1g7swaw/wheels/cf/59/82/6492402e887a68975030bf8c06532260abc16abb7ccd8127cc\n",
      "Successfully built transformers\n",
      "Installing collected packages: safetensors, bitsandbytes, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed bitsandbytes-0.41.1 huggingface-hub-0.16.4 regex-2023.8.8 safetensors-0.3.3 tokenizers-0.14.0 transformers-4.34.0.dev0\n",
      "Collecting git+https://github.com/huggingface/peft.git@4c611f4\n",
      "  Cloning https://github.com/huggingface/peft.git (to revision 4c611f4) to /var/tmp/pip-req-build-my904n1t\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /var/tmp/pip-req-build-my904n1t\n",
      "\u001b[33m  WARNING: Did not find branch or tag '4c611f4', assuming revision or ref.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Running command git checkout -q 4c611f4\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 4c611f4\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (6.0.1)\n",
      "Collecting torch>=1.13.0 (from peft==0.6.0.dev0)\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (4.34.0.dev0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (4.66.1)\n",
      "Collecting accelerate>=0.21.0 (from peft==0.6.0.dev0)\n",
      "  Obtaining dependency information for accelerate>=0.21.0 from https://files.pythonhosted.org/packages/d9/92/2d3aecf9f4a192968035880be3e2fc8b48d541c7128f7c936f430d6f96da/accelerate-0.23.0-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0) (0.3.3)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->peft==0.6.0.dev0) (0.16.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (4.7.1)\n",
      "Collecting sympy (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.6.0.dev0) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting triton==2.0.0 (from torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.6.0.dev0) (68.1.2)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.6.0.dev0) (0.41.2)\n",
      "Collecting cmake (from triton==2.0.0->torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Obtaining dependency information for cmake from https://files.pythonhosted.org/packages/de/94/cba4b3ddc0d4555967cce8fd6e9fbced98a6bf62857db71c2400a7b6e183/cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
      "  Downloading cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting lit (from triton==2.0.0->torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached lit-16.0.6.tar.gz (153 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.6.0.dev0) (2023.8.8)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.6.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.6.0.dev0) (0.14.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.21.0->peft==0.6.0.dev0) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.6.0.dev0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.6.0.dev0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.6.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.6.0.dev0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft==0.6.0.dev0) (2023.7.22)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.13.0->peft==0.6.0.dev0)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached accelerate-0.23.0-py3-none-any.whl (258 kB)\n",
      "Using cached cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n",
      "Building wheels for collected packages: peft, lit\n",
      "  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peft: filename=peft-0.6.0.dev0-py3-none-any.whl size=107773 sha256=55197961f33e97b38b3737c5f2a26c3a6567fc565aab9dae1fddc65a34bc959d\n",
      "  Stored in directory: /var/tmp/pip-ephem-wheel-cache-sk1qcdl0/wheels/09/7c/24/ec39b8742e1a5e1de8dab6e557914d7709f4d5797838ab104f\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.6-py3-none-any.whl size=93584 sha256=06015d23e2eea9455746d7ef7be098a96fce991bd41c77c985ccde6fe8148979\n",
      "  Stored in directory: /home/sam/.cache/pip/wheels/14/f9/07/bb2308587bc2f57158f905a2325f6a89a2befa7437b2d7e137\n",
      "Successfully built peft lit\n",
      "Installing collected packages: mpmath, lit, cmake, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, accelerate, peft\n",
      "Successfully installed accelerate-0.23.0 cmake-3.27.5 lit-16.0.6 mpmath-1.3.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 peft-0.6.0.dev0 sympy-1.12 torch-2.0.1 triton-2.0.0\n",
      "Collecting datasets==2.10.1\n",
      "  Using cached datasets-2.10.1-py3-none-any.whl (469 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (12.0.1)\n",
      "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.10.1)\n",
      "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (4.66.1)\n",
      "Collecting xxhash (from datasets==2.10.1)\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/13/c3/e942893f4864a424514c81640f114980cfd5aff7e7414d1e0255f4571111/xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets==2.10.1)\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/35/a8/36d8d7b3e46b377800d8dec47891cdf05842d1a2366909ae4a0c89fbc5e6/multiprocess-0.70.15-py310-none-any.whl.metadata\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (0.16.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (23.1)\n",
      "Collecting responses<0.19 (from datasets==2.10.1)\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.10.1) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.10.1) (1.3.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.10.1) (2023.7.22)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets==2.10.1)\n",
      "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.10.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.10.1) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.10.1) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.10.1) (1.16.0)\n",
      "Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, dill, responses, multiprocess, datasets\n",
      "Successfully installed datasets-2.10.1 dill-0.3.6 multiprocess-0.70.14 responses-0.18.0 xxhash-3.3.0\n",
      "Collecting wandb\n",
      "  Obtaining dependency information for wandb from https://files.pythonhosted.org/packages/fe/10/18b03623c460fd433525d9b4739af58c5e69f5974328dcdd037cfbc855d7/wandb-0.15.10-py3-none-any.whl.metadata\n",
      "  Downloading wandb-0.15.10-py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.32)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Obtaining dependency information for sentry-sdk>=1.0.0 from https://files.pythonhosted.org/packages/62/3a/765a7699a26884dcbf8b071dbe2a2486cc1cafcfb5f5d2e64ffe745dd0c6/sentry_sdk-1.31.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
      "Collecting pathtools (from wandb)\n",
      "  Using cached pathtools-0.1.2.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (68.1.2)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
      "Using cached wandb-0.15.10-py3-none-any.whl (2.1 MB)\n",
      "Using cached sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n",
      "Building wheels for collected packages: pathtools\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=2b1e2b5b78f8e6454eaa12864590fa78ca089037ec061b2e4e4475a6c6763130\n",
      "  Stored in directory: /home/sam/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
      "Successfully built pathtools\n",
      "Installing collected packages: pathtools, appdirs, setproctitle, sentry-sdk, docker-pycreds, wandb\n",
      "Successfully installed appdirs-1.4.4 docker-pycreds-0.4.0 pathtools-0.1.2 sentry-sdk-1.31.0 setproctitle-1.3.2 wandb-0.15.10\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git@main bitsandbytes  # we need latest transformers for this\n",
    "!pip install git+https://github.com/huggingface/peft.git@4c611f4\n",
    "!pip install datasets==2.10.1\n",
    "import locale # colab workaround\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\" # colab workaround\n",
    "!pip install wandb\n",
    "!pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../embeddings/\")\n",
    "\n",
    "from chroma_funcs import get_closest_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_examples(examples):\n",
    "    result = \"Given the following examples:\\n\"\n",
    "    for i, example_group in enumerate(examples):\n",
    "        for j, example in enumerate(example_group):\n",
    "            result += f\"Example {j+1}:\"\n",
    "            result += \"\\n### Input:\\n\"\n",
    "            result += example.get('question', 'N/A') + \"\\n\"\n",
    "            result += \"\\n### Context:\\n\"\n",
    "            result += example.get('context', 'N/A') + \"\\n\"\n",
    "            result += \"\\n### Response:\\n\"\n",
    "            result += example.get('answer', 'N/A') + \"\\n\\n\"\n",
    "        if i < len(examples) - 1:\n",
    "            result += \"\\n\"\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_rag_sql_prompt(data_point, dataset_name):\n",
    "    results = get_closest_entries(\n",
    "        dataset_name,\n",
    "        \"question\",\n",
    "        data_point[\"question\"],\n",
    "        n_results=5,\n",
    "        dataset_split=\"train\",\n",
    "    )\n",
    "\n",
    "    rag_datapoints = results[\"metadatas\"]\n",
    "    # print(\"rag datapoints are: \", rag_datapoints)\n",
    "    formatted_examples = format_examples(rag_datapoints)\n",
    "    # print(\"formatted examples are: \", formatted_examples)\n",
    "    inference_prompt = f\"\"\"You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables. You must output the SQL query that answers the question.\n",
    "\n",
    "{formatted_examples}Please generate the SQL query that answers the following:\n",
    "### Input:\n",
    "{data_point[\"question\"]}\n",
    "\n",
    "### Context:\n",
    "{data_point[\"context\"]}\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "    full_prompt = f\"{inference_prompt}\\n{data_point['answer']}\"\n",
    "    return full_prompt, inference_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collection.count() 6602\n",
      "collection.count() 6602\n",
      "[[{'answer': 'SELECT AVG(Working_Horses) FROM farm WHERE Total_Horses > 5000', 'context': 'CREATE TABLE farm (Working_Horses INTEGER, Total_Horses INTEGER)', 'question': 'What is the average number of working horses of farms with more than 5000 total number of horses?'}, {'answer': 'SELECT AVG(Working_Horses) FROM farm WHERE Total_Horses > 5000', 'context': 'CREATE TABLE farm (Working_Horses INTEGER, Total_Horses INTEGER)', 'question': 'What is the average number of working horses of farms with more than 5000 total number of horses?'}, {'answer': 'SELECT AVG(Price), AVG(Cases) FROM WINE WHERE YEAR = 2009 AND Grape = \"Zinfandel\"', 'context': 'CREATE TABLE WINE (Price INTEGER, Cases INTEGER, YEAR VARCHAR, Grape VARCHAR)', 'question': 'What are the average prices and cases of wines produced in the year of 2009 and made of Zinfandel grape?'}, {'answer': 'SELECT AVG(Price), AVG(Cases) FROM WINE WHERE YEAR = 2009 AND Grape = \"Zinfandel\"', 'context': 'CREATE TABLE WINE (Price INTEGER, Cases INTEGER, YEAR VARCHAR, Grape VARCHAR)', 'question': 'What are the average prices and cases of wines produced in the year of 2009 and made of Zinfandel grape?'}, {'answer': 'SELECT Price FROM WINE WHERE YEAR < 2010', 'context': 'CREATE TABLE WINE (Price VARCHAR, YEAR INTEGER)', 'question': 'What are the prices of wines produced before the year of 2010?'}]]\n",
      "You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables. You must output the SQL query that answers the question.\n",
      "\n",
      "Given the following examples:\n",
      "Example 1:\n",
      "### Input:\n",
      "What is the average number of working horses of farms with more than 5000 total number of horses?\n",
      "\n",
      "### Context:\n",
      "CREATE TABLE farm (Working_Horses INTEGER, Total_Horses INTEGER)\n",
      "\n",
      "### Response:\n",
      "SELECT AVG(Working_Horses) FROM farm WHERE Total_Horses > 5000\n",
      "\n",
      "Example 2:\n",
      "### Input:\n",
      "What is the average number of working horses of farms with more than 5000 total number of horses?\n",
      "\n",
      "### Context:\n",
      "CREATE TABLE farm (Working_Horses INTEGER, Total_Horses INTEGER)\n",
      "\n",
      "### Response:\n",
      "SELECT AVG(Working_Horses) FROM farm WHERE Total_Horses > 5000\n",
      "\n",
      "Example 3:\n",
      "### Input:\n",
      "What are the average prices and cases of wines produced in the year of 2009 and made of Zinfandel grape?\n",
      "\n",
      "### Context:\n",
      "CREATE TABLE WINE (Price INTEGER, Cases INTEGER, YEAR VARCHAR, Grape VARCHAR)\n",
      "\n",
      "### Response:\n",
      "SELECT AVG(Price), AVG(Cases) FROM WINE WHERE YEAR = 2009 AND Grape = \"Zinfandel\"\n",
      "\n",
      "Example 4:\n",
      "### Input:\n",
      "What are the average prices and cases of wines produced in the year of 2009 and made of Zinfandel grape?\n",
      "\n",
      "### Context:\n",
      "CREATE TABLE WINE (Price INTEGER, Cases INTEGER, YEAR VARCHAR, Grape VARCHAR)\n",
      "\n",
      "### Response:\n",
      "SELECT AVG(Price), AVG(Cases) FROM WINE WHERE YEAR = 2009 AND Grape = \"Zinfandel\"\n",
      "\n",
      "Example 5:\n",
      "### Input:\n",
      "What are the prices of wines produced before the year of 2010?\n",
      "\n",
      "### Context:\n",
      "CREATE TABLE WINE (Price VARCHAR, YEAR INTEGER)\n",
      "\n",
      "### Response:\n",
      "SELECT Price FROM WINE WHERE YEAR < 2010\n",
      "\n",
      "Please generate the SQL query that answers the following:\n",
      "### Input:\n",
      "What is the average horsepower for all cars produced before 1980 ?\n",
      "\n",
      "### Context:\n",
      "CREATE TABLE cars_data (horsepower INTEGER, year INTEGER)\n",
      "\n",
      "### Response:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_datapoint = {\n",
    "        \"question\": \"What is the average horsepower for all cars produced before 1980 ?\",\n",
    "        \"context\": \"CREATE TABLE cars_data (horsepower INTEGER, year INTEGER)\",\n",
    "        \"answer\": \"select avg(horsepower) from cars_data where year  <  1980;\",\n",
    "        \"db_id\": \"car_1\"\n",
    "    }\n",
    "\n",
    "print(generate_rag_sql_prompt(test_datapoint, \"samlhuillier/sql-create-context-spider-intersect\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 936/936 [01:51<00:00,  8.41 examples/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 15.91ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4106046"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"samlhuillier/sql-create-context-spider-intersect\", split=\"validation\")\n",
    "\n",
    "def add_prompt_features(example):\n",
    "    # Add your logic to generate the extra feature here\n",
    "    full_prompt, inference_prompt = generate_rag_sql_prompt(example, \"samlhuillier/sql-create-context-spider-intersect\")\n",
    "    example['full_prompt'] = full_prompt\n",
    "    example['inference_prompt'] = inference_prompt\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(add_prompt_features)\n",
    "\n",
    "# Step 4: Save the dataset as a JSON file\n",
    "dataset.to_json('sql-create-context-spider-intersect-validation-with-prompts.jsonl')\n",
    "# prompts = []\n",
    "# for data_point in dataset:\n",
    "#     prompts.append(generate_rag_sql_prompt(data_point, \"samlhuillier/sql-create-context-spider-intersect\"))\n",
    "#     # print(generate_rag_sql_prompt(data_point, \"samlhuillier/sql-create-context-spider-intersect\"))\n",
    "\n",
    "# print(prompts[8])\n",
    "# prompted_dataset = dataset.map(\n",
    "#     lambda x: generate_rag_sql_prompt(x, \"samlhuillier/sql-create-context-spider-intersect\")\n",
    "# )\n",
    "# prompted_dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables. You must output the SQL query that answers the question.\\n\\nGiven the following examples:\\nExample 1:\\n### Input:\\nList the age of all music artists.\\n\\n### Context:\\nCREATE TABLE artist (Age VARCHAR)\\n\\n### Response:\\nSELECT Age FROM artist\\n\\nExample 2:\\n### Input:\\nList the age of all music artists.\\n\\n### Context:\\nCREATE TABLE artist (Age VARCHAR)\\n\\n### Response:\\nSELECT Age FROM artist\\n\\nExample 3:\\n### Input:\\nPlease list the age and famous title of artists in descending order of age.\\n\\n### Context:\\nCREATE TABLE artist (Famous_Title VARCHAR, Age VARCHAR)\\n\\n### Response:\\nSELECT Famous_Title, Age FROM artist ORDER BY Age DESC\\n\\nExample 4:\\n### Input:\\nPlease list the age and famous title of artists in descending order of age.\\n\\n### Context:\\nCREATE TABLE artist (Famous_Title VARCHAR, Age VARCHAR)\\n\\n### Response:\\nSELECT Famous_Title, Age FROM artist ORDER BY Age DESC\\n\\nExample 5:\\n### Input:\\nShow all artist name, age, and country ordered by the yeared they joined.\\n\\n### Context:\\nCREATE TABLE artist (name VARCHAR, age VARCHAR, country VARCHAR, Year_Join VARCHAR)\\n\\n### Response:\\nSELECT name, age, country FROM artist ORDER BY Year_Join\\n\\nPlease generate the SQL query that answers the following:\\n### Input:\\nShow name, country, age for all singers ordered by age from the oldest to the youngest.\\n\\n### Context:\\nCREATE TABLE singer (name VARCHAR, country VARCHAR, age VARCHAR)\\n\\n### Response:\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# with open(\"sql-create-context-spider-intersect-validation-with-prompts.jsonl\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "\n",
    "# with open('sql-create-context-spider-intersect-validation-with-prompts.jsonl', 'r') as f:\n",
    "#     for line in f:\n",
    "#         data = json.loads(line)\n",
    "#         # print(data)\n",
    "\n",
    "data = []\n",
    "with open('sql-create-context-spider-intersect-validation-with-prompts.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "# print(data_list[2])\n",
    "# Step 2: Apply the function to each entry\n",
    "# responses = map(your_function, data)\n",
    "prompts = []\n",
    "for data_point in data:\n",
    "    # prompt = generate_prompt(data_point)\n",
    "    # append prompt to prompts\n",
    "    prompts.append(data_point['inference_prompt'])\n",
    "\n",
    "prompts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/root/google_vm_config.lock'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/sam/finetune-llm-for-rag/inference/yes-rag-inference-for-sql-queries-list-llama.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgcp/home/sam/finetune-llm-for-rag/inference/yes-rag-inference-for-sql-queries-list-llama.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     MatmulLtState,\n\u001b[1;32m      9\u001b[0m     bmm_cublas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     matmul_4bit\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/research/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     switchback_bnb,\n\u001b[1;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[1;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/research/nn/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/research/nn/modules.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor, device, dtype, nn\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mimport\u001b[39;00m GlobalOptimManager\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n\u001b[1;32m     11\u001b[0m T \u001b[39m=\u001b[39m TypeVar(\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, bound\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorch.nn.Module\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/optim/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madagrad\u001b[39;00m \u001b[39mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madam\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam, Adam8bit, Adam32bit, PagedAdam, PagedAdam8bit, PagedAdam32bit\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/cextension.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m setup \u001b[39m=\u001b[39m CUDASetup\u001b[39m.\u001b[39mget_instance()\n\u001b[1;32m     12\u001b[0m \u001b[39mif\u001b[39;00m setup\u001b[39m.\u001b[39minitialized \u001b[39m!=\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     setup\u001b[39m.\u001b[39;49mrun_cuda_setup()\n\u001b[1;32m     15\u001b[0m lib \u001b[39m=\u001b[39m setup\u001b[39m.\u001b[39mlib\n\u001b[1;32m     16\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:120\u001b[0m, in \u001b[0;36mCUDASetup.run_cuda_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitialized \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcuda_setup_log \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 120\u001b[0m binary_name, cudart_path, cc, cuda_version_string \u001b[39m=\u001b[39m evaluate_cuda_setup()\n\u001b[1;32m    121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcudart_path \u001b[39m=\u001b[39m cudart_path\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcuda_available \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:337\u001b[0m, in \u001b[0;36mevaluate_cuda_setup\u001b[0;34m()\u001b[0m\n\u001b[1;32m    334\u001b[0m     cuda_setup\u001b[39m.\u001b[39madd_log_entry(\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m80\u001b[39m)\n\u001b[1;32m    335\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available(): \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mlibbitsandbytes_cpu.so\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m cudart_path \u001b[39m=\u001b[39m determine_cuda_runtime_lib_path()\n\u001b[1;32m    338\u001b[0m ccs \u001b[39m=\u001b[39m get_compute_capabilities()\n\u001b[1;32m    339\u001b[0m ccs\u001b[39m.\u001b[39msort()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:295\u001b[0m, in \u001b[0;36mdetermine_cuda_runtime_lib_path\u001b[0;34m()\u001b[0m\n\u001b[1;32m    293\u001b[0m cuda_runtime_libs \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    294\u001b[0m \u001b[39mfor\u001b[39;00m env_var, value \u001b[39min\u001b[39;00m remaining_candidate_env_vars\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 295\u001b[0m     cuda_runtime_libs\u001b[39m.\u001b[39mupdate(find_cuda_lib_in(value))\n\u001b[1;32m    297\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cuda_runtime_libs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    298\u001b[0m     CUDASetup\u001b[39m.\u001b[39mget_instance()\u001b[39m.\u001b[39madd_log_entry(\u001b[39m'\u001b[39m\u001b[39mCUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:232\u001b[0m, in \u001b[0;36mfind_cuda_lib_in\u001b[0;34m(paths_list_candidate)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_cuda_lib_in\u001b[39m(paths_list_candidate: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Set[Path]:\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m get_cuda_runtime_lib_paths(\n\u001b[0;32m--> 232\u001b[0m         resolve_paths_list(paths_list_candidate)\n\u001b[1;32m    233\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:227\u001b[0m, in \u001b[0;36mresolve_paths_list\u001b[0;34m(paths_list_candidate)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresolve_paths_list\u001b[39m(paths_list_candidate: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Set[Path]:\n\u001b[1;32m    223\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39m    Searches a given environmental var for the CUDA runtime library,\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39m    i.e. `libcudart.so`.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     \u001b[39mreturn\u001b[39;00m remove_non_existent_dirs(extract_candidate_paths(paths_list_candidate))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:201\u001b[0m, in \u001b[0;36mremove_non_existent_dirs\u001b[0;34m(candidate_paths)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    200\u001b[0m     \u001b[39mif\u001b[39;00m exc\u001b[39m.\u001b[39merrno \u001b[39m!=\u001b[39m errno\u001b[39m.\u001b[39mENAMETOOLONG:\n\u001b[0;32m--> 201\u001b[0m         \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mPermissionError\u001b[39;00m \u001b[39mas\u001b[39;00m pex:\n\u001b[1;32m    203\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:197\u001b[0m, in \u001b[0;36mremove_non_existent_dirs\u001b[0;34m(candidate_paths)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mfor\u001b[39;00m path \u001b[39min\u001b[39;00m candidate_paths:\n\u001b[1;32m    196\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39;49mexists():\n\u001b[1;32m    198\u001b[0m             existent_directories\u001b[39m.\u001b[39madd(path)\n\u001b[1;32m    199\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:1290\u001b[0m, in \u001b[0;36mPath.exists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m \u001b[39mWhether this path exists.\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1290\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstat()\n\u001b[1;32m   1291\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1292\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _ignore_error(e):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:1097\u001b[0m, in \u001b[0;36mPath.stat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstat\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, follow_symlinks\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1093\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m \u001b[39m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m \u001b[39m    os.stat() does.\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mstat(\u001b[39mself\u001b[39;49m, follow_symlinks\u001b[39m=\u001b[39;49mfollow_symlinks)\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/root/google_vm_config.lock'"
     ]
    }
   ],
   "source": [
    "import bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:87: RequestsDependencyWarning: urllib3 (2.0.5) or chardet (4.0.0) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/sam/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 637/637 [00:00<00:00, 162kB/s]\n",
      "Downloading (…)fetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 6.53MB/s]\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 9.98G/9.98G [00:33<00:00, 302MB/s]\n",
      "Downloading (…)of-00002.safetensors: 100%|██████████| 3.50G/3.50G [00:10<00:00, 326MB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [00:44<00:00, 22.01s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):\n[Errno 13] Permission denied: '/root/google_vm_config.lock'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py:1229\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1229\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m module_name, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[1;32m   1230\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:790\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/integrations/bitsandbytes.py:11\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mif\u001b[39;00m is_bitsandbytes_available():\n\u001b[0;32m---> 11\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     MatmulLtState,\n\u001b[1;32m      9\u001b[0m     bmm_cublas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     matmul_4bit\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/research/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     switchback_bnb,\n\u001b[1;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[1;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/research/nn/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/research/nn/modules.py:8\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mimport\u001b[39;00m GlobalOptimManager\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/optim/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madagrad\u001b[39;00m \u001b[39mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/cextension.py:13\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mif\u001b[39;00m setup\u001b[39m.\u001b[39minitialized \u001b[39m!=\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     setup\u001b[39m.\u001b[39;49mrun_cuda_setup()\n\u001b[1;32m     15\u001b[0m lib \u001b[39m=\u001b[39m setup\u001b[39m.\u001b[39mlib\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:120\u001b[0m, in \u001b[0;36mCUDASetup.run_cuda_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcuda_setup_log \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 120\u001b[0m binary_name, cudart_path, cc, cuda_version_string \u001b[39m=\u001b[39m evaluate_cuda_setup()\n\u001b[1;32m    121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcudart_path \u001b[39m=\u001b[39m cudart_path\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:337\u001b[0m, in \u001b[0;36mevaluate_cuda_setup\u001b[0;34m()\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available(): \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mlibbitsandbytes_cpu.so\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m cudart_path \u001b[39m=\u001b[39m determine_cuda_runtime_lib_path()\n\u001b[1;32m    338\u001b[0m ccs \u001b[39m=\u001b[39m get_compute_capabilities()\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:295\u001b[0m, in \u001b[0;36mdetermine_cuda_runtime_lib_path\u001b[0;34m()\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mfor\u001b[39;00m env_var, value \u001b[39min\u001b[39;00m remaining_candidate_env_vars\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 295\u001b[0m     cuda_runtime_libs\u001b[39m.\u001b[39mupdate(find_cuda_lib_in(value))\n\u001b[1;32m    297\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(cuda_runtime_libs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:232\u001b[0m, in \u001b[0;36mfind_cuda_lib_in\u001b[0;34m(paths_list_candidate)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_cuda_lib_in\u001b[39m(paths_list_candidate: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Set[Path]:\n\u001b[1;32m    231\u001b[0m     \u001b[39mreturn\u001b[39;00m get_cuda_runtime_lib_paths(\n\u001b[0;32m--> 232\u001b[0m         resolve_paths_list(paths_list_candidate)\n\u001b[1;32m    233\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:227\u001b[0m, in \u001b[0;36mresolve_paths_list\u001b[0;34m(paths_list_candidate)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[39mSearches a given environmental var for the CUDA runtime library,\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \u001b[39mi.e. `libcudart.so`.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m \u001b[39mreturn\u001b[39;00m remove_non_existent_dirs(extract_candidate_paths(paths_list_candidate))\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:201\u001b[0m, in \u001b[0;36mremove_non_existent_dirs\u001b[0;34m(candidate_paths)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[39mif\u001b[39;00m exc\u001b[39m.\u001b[39merrno \u001b[39m!=\u001b[39m errno\u001b[39m.\u001b[39mENAMETOOLONG:\n\u001b[0;32m--> 201\u001b[0m         \u001b[39mraise\u001b[39;00m exc\n\u001b[1;32m    202\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mPermissionError\u001b[39;00m \u001b[39mas\u001b[39;00m pex:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:197\u001b[0m, in \u001b[0;36mremove_non_existent_dirs\u001b[0;34m(candidate_paths)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m     \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39;49mexists():\n\u001b[1;32m    198\u001b[0m         existent_directories\u001b[39m.\u001b[39madd(path)\n",
      "File \u001b[0;32m/usr/lib/python3.9/pathlib.py:1407\u001b[0m, in \u001b[0;36mPath.exists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1407\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstat()\n\u001b[1;32m   1408\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.9/pathlib.py:1221\u001b[0m, in \u001b[0;36mPath.stat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m \u001b[39mReturn the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m \u001b[39mos.stat() does.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1221\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mstat(\u001b[39mself\u001b[39;49m)\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/root/google_vm_config.lock'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/sam/finetune-llm-for-rag/inference/yes-rag-inference-for-sql-queries-list-llama.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcp/home/sam/finetune-llm-for-rag/inference/yes-rag-inference-for-sql-queries-list-llama.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcp/home/sam/finetune-llm-for-rag/inference/yes-rag-inference-for-sql-queries-list-llama.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m base_model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcodellama/CodeLlama-7b-hf\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgcp/home/sam/finetune-llm-for-rag/inference/yes-rag-inference-for-sql-queries-list-llama.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcp/home/sam/finetune-llm-for-rag/inference/yes-rag-inference-for-sql-queries-list-llama.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     base_model,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcp/home/sam/finetune-llm-for-rag/inference/yes-rag-inference-for-sql-queries-list-llama.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     load_in_8bit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcp/home/sam/finetune-llm-for-rag/inference/yes-rag-inference-for-sql-queries-list-llama.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgcp/home/sam/finetune-llm-for-rag/inference/yes-rag-inference-for-sql-queries-list-llama.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcp/home/sam/finetune-llm-for-rag/inference/yes-rag-inference-for-sql-queries-list-llama.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgcp/home/sam/finetune-llm-for-rag/inference/yes-rag-inference-for-sql-queries-list-llama.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mcodellama/CodeLlama-7b-hf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:563\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m(config) \u001b[39min\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    562\u001b[0m     model_class \u001b[39m=\u001b[39m _get_model_class(config, \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    564\u001b[0m         pretrained_model_name_or_path, \u001b[39m*\u001b[39;49mmodel_args, config\u001b[39m=\u001b[39;49mconfig, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mhub_kwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    565\u001b[0m     )\n\u001b[1;32m    566\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized configuration class \u001b[39m\u001b[39m{\u001b[39;00mconfig\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m for this kind of AutoModel: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel type should be one of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(c\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m \u001b[39m\u001b[39mfor\u001b[39;00m\u001b[39m \u001b[39mc\u001b[39m \u001b[39m\u001b[39min\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_model_mapping\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:2999\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2996\u001b[0m     keep_in_fp32_modules \u001b[39m=\u001b[39m []\n\u001b[1;32m   2998\u001b[0m \u001b[39mif\u001b[39;00m load_in_8bit \u001b[39mor\u001b[39;00m load_in_4bit:\n\u001b[0;32m-> 2999\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mintegrations\u001b[39;00m \u001b[39mimport\u001b[39;00m get_keys_to_not_convert, replace_with_bnb_linear\n\u001b[1;32m   3001\u001b[0m     llm_int8_skip_modules \u001b[39m=\u001b[39m quantization_config\u001b[39m.\u001b[39mllm_int8_skip_modules\n\u001b[1;32m   3002\u001b[0m     load_in_8bit_fp32_cpu_offload \u001b[39m=\u001b[39m quantization_config\u001b[39m.\u001b[39mllm_int8_enable_fp32_cpu_offload\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py:1219\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1217\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(name)\n\u001b[1;32m   1218\u001b[0m \u001b[39melif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_class_to_module\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m-> 1219\u001b[0m     module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_class_to_module[name])\n\u001b[1;32m   1220\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1221\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py:1231\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[39mreturn\u001b[39;00m importlib\u001b[39m.\u001b[39mimport_module(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m module_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1230\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1231\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1232\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to import \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mmodule_name\u001b[39m}\u001b[39;00m\u001b[39m because of the following error (look up to see its\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1233\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m traceback):\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1234\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):\n[Errno 13] Permission denied: '/root/google_vm_config.lock'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "\n",
    "base_model = \"codellama/CodeLlama-7b-hf\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import PeftModel\n",
    "\n",
    "# model = PeftModel.from_pretrained(model, \"sql-code-llama/checkpoint-160\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # You can adjust the batch size based on your GPU capacity\n",
    "outputs = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad(), open(\"codellama7b-outputs-with-rag.txt\", \"a\") as f:\n",
    "    for i in range(0, len(prompts), batch_size):\n",
    "        print(\"i is: \", i)\n",
    "        batch_inputs = prompts[i : i + batch_size]\n",
    "\n",
    "        # Step 3: Loop over the batches and generate the outputs\n",
    "        batch_model_inputs = tokenizer(\n",
    "            batch_inputs, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )\n",
    "\n",
    "        input_lengths = [\n",
    "            len(input_ids) for input_ids in batch_model_inputs[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "        batch_outputs = model.generate(**batch_model_inputs, max_new_tokens=100)\n",
    "\n",
    "        # Step 4: Collect the outputs\n",
    "        batch_decoded_outputs = [\n",
    "            tokenizer.decode(output[input_length:], skip_special_tokens=True)\n",
    "            for output, input_length in zip(batch_outputs, input_lengths)\n",
    "        ]\n",
    "        outputs.extend(batch_decoded_outputs)\n",
    "        print(outputs)\n",
    "        for b in batch_decoded_outputs:\n",
    "            f.write(b.replace(\"\\n\", \" \") + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

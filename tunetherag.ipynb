{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from embeddings.chroma_funcs import (\n",
    "    generate_knowledge_base_from_hf_dataset,\n",
    ")\n",
    "from chromadb.utils import embedding_functions\n",
    "from augment_dataset import augment_dataset_with_prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    model_name=\"text-embedding-ada-002\",\n",
    "    # api_key=\"\", # add api key if it's not set in your env\n",
    ")\n",
    "\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embd_fn <chromadb.utils.embedding_functions.OpenAIEmbeddingFunction object at 0x7fd7eea70340>\n",
      "Collection.count is:  7473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset gsm8k (/Users/sam/.cache/huggingface/datasets/gsm8k/main/1.1.0/37bfb08b1d4fcbb01f06b03d9e1ef5f1fcbd4d3af3d08842c50d7305091285ba)\n",
      "100%|██████████| 2/2 [00:00<00:00, 316.36it/s]\n",
      "Parameter 'function'=<function augment_dataset_with_prompts.<locals>.<lambda> at 0x7fd7ebf1a830> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer'],\n",
      "    num_rows: 7473\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sam/Desktop/finetune-llm-for-rag/tunetherag.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sam/Desktop/finetune-llm-for-rag/tunetherag.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m full_prompt, inference_prompt\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sam/Desktop/finetune-llm-for-rag/tunetherag.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSolve the following math problem thinking step-by-step:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sam/Desktop/finetune-llm-for-rag/tunetherag.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m augment_dataset_with_prompts(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sam/Desktop/finetune-llm-for-rag/tunetherag.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     dataset_parameters, knowledge_base, embedding_feature, format_math_example, prompt, n_examples\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sam/Desktop/finetune-llm-for-rag/tunetherag.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/finetune-llm-for-rag/augment_dataset.py:35\u001b[0m, in \u001b[0;36maugment_dataset_with_prompts\u001b[0;34m(dataset_args, knowledge_base, embed_feature, format_example, prompt, n_examples)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mfor\u001b[39;00m split, dataset \u001b[39min\u001b[39;00m dataset_dict\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     34\u001b[0m     \u001b[39mprint\u001b[39m(dataset)\n\u001b[0;32m---> 35\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m     36\u001b[0m         \u001b[39mlambda\u001b[39;49;00m example: add_prompt_features(\n\u001b[1;32m     37\u001b[0m             example,\n\u001b[1;32m     38\u001b[0m             knowledge_base,\n\u001b[1;32m     39\u001b[0m             embed_feature,\n\u001b[1;32m     40\u001b[0m             format_example,\n\u001b[1;32m     41\u001b[0m             prompt,\n\u001b[1;32m     42\u001b[0m             n_examples,\n\u001b[1;32m     43\u001b[0m         ),\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     46\u001b[0m     \u001b[39m# TODO: add in embedding function:\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     embedding_function \u001b[39m=\u001b[39m get_embedding_model_name(\n\u001b[1;32m     48\u001b[0m         knowledge_base\u001b[39m.\u001b[39m_embedding_function\n\u001b[1;32m     49\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:563\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    562\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 563\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    564\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    565\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    566\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:528\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    522\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    524\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    526\u001b[0m }\n\u001b[1;32m    527\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    529\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    530\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:2953\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2945\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2946\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   2947\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   2948\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2951\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2952\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 2953\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   2954\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   2955\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:3307\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3305\u001b[0m _time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m   3306\u001b[0m \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3307\u001b[0m     example \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[39m=\u001b[39;49moffset)\n\u001b[1;32m   3308\u001b[0m     \u001b[39mif\u001b[39;00m update_data:\n\u001b[1;32m   3309\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/datasets/arrow_dataset.py:3210\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3208\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   3209\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 3210\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   3211\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3212\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[1;32m   3213\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[1;32m   3214\u001b[0m     }\n",
      "File \u001b[0;32m~/Desktop/finetune-llm-for-rag/augment_dataset.py:36\u001b[0m, in \u001b[0;36maugment_dataset_with_prompts.<locals>.<lambda>\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mfor\u001b[39;00m split, dataset \u001b[39min\u001b[39;00m dataset_dict\u001b[39m.\u001b[39mitems():\n\u001b[1;32m     34\u001b[0m     \u001b[39mprint\u001b[39m(dataset)\n\u001b[1;32m     35\u001b[0m     dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(\n\u001b[0;32m---> 36\u001b[0m         \u001b[39mlambda\u001b[39;00m example: add_prompt_features(\n\u001b[1;32m     37\u001b[0m             example,\n\u001b[1;32m     38\u001b[0m             knowledge_base,\n\u001b[1;32m     39\u001b[0m             embed_feature,\n\u001b[1;32m     40\u001b[0m             format_example,\n\u001b[1;32m     41\u001b[0m             prompt,\n\u001b[1;32m     42\u001b[0m             n_examples,\n\u001b[1;32m     43\u001b[0m         ),\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     46\u001b[0m     \u001b[39m# TODO: add in embedding function:\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     embedding_function \u001b[39m=\u001b[39m get_embedding_model_name(\n\u001b[1;32m     48\u001b[0m         knowledge_base\u001b[39m.\u001b[39m_embedding_function\n\u001b[1;32m     49\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/finetune-llm-for-rag/augment_dataset.py:18\u001b[0m, in \u001b[0;36madd_prompt_features\u001b[0;34m(example, knowledge_base, embed_feature, format_example, prompt, n_examples)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_prompt_features\u001b[39m(\n\u001b[1;32m     15\u001b[0m     example, knowledge_base, embed_feature, format_example, prompt, n_examples\n\u001b[1;32m     16\u001b[0m ):\n\u001b[1;32m     17\u001b[0m     \u001b[39m# Add your logic to generate the extra feature here\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     full_prompt, inference_prompt \u001b[39m=\u001b[39m generate_generic_prompt(\n\u001b[1;32m     19\u001b[0m         knowledge_base, example, embed_feature, n_examples, prompt, format_example\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     example[\u001b[39m\"\u001b[39m\u001b[39mfull_prompt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m full_prompt\n\u001b[1;32m     23\u001b[0m     example[\u001b[39m\"\u001b[39m\u001b[39minference_prompt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m inference_prompt\n",
      "File \u001b[0;32m~/Desktop/finetune-llm-for-rag/prompt_setup.py:192\u001b[0m, in \u001b[0;36mgenerate_generic_prompt\u001b[0;34m(knowledge_base, data_point, embed_feature, n_examples, prompt, format_example)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_generic_prompt\u001b[39m(\n\u001b[1;32m    190\u001b[0m     knowledge_base, data_point, embed_feature, n_examples, prompt, format_example\n\u001b[1;32m    191\u001b[0m ):\n\u001b[0;32m--> 192\u001b[0m     examples \u001b[39m=\u001b[39m get_examples_from_db(\n\u001b[1;32m    193\u001b[0m         knowledge_base, data_point, embed_feature, n_examples\n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    195\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(examples) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    196\u001b[0m         formatted_examples \u001b[39m=\u001b[39m format_rag_examples(examples, format_example)\n",
      "File \u001b[0;32m~/Desktop/finetune-llm-for-rag/prompt_setup.py:152\u001b[0m, in \u001b[0;36mget_examples_from_db\u001b[0;34m(knowledge_base, data_point, embed_feature, n_examples)\u001b[0m\n\u001b[1;32m    150\u001b[0m examples \u001b[39m=\u001b[39m []\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m n_examples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 152\u001b[0m     examples \u001b[39m=\u001b[39m get_closest_entries(\n\u001b[1;32m    153\u001b[0m         knowledge_base,\n\u001b[1;32m    154\u001b[0m         data_point[embed_feature],\n\u001b[1;32m    155\u001b[0m         embed_feature,\n\u001b[1;32m    156\u001b[0m         n_results\u001b[39m=\u001b[39;49mn_examples,\n\u001b[1;32m    157\u001b[0m     )[\u001b[39m\"\u001b[39m\u001b[39mmetadatas\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    158\u001b[0m \u001b[39mreturn\u001b[39;00m examples\n",
      "File \u001b[0;32m~/Desktop/finetune-llm-for-rag/embeddings/chroma_funcs.py:93\u001b[0m, in \u001b[0;36mget_closest_entries\u001b[0;34m(collection, query, embed_feature, n_results, db_id)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_closest_entries\u001b[39m(\n\u001b[1;32m     91\u001b[0m     collection, query, embed_feature, n_results\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, db_id\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msdojfaosdijfaposdfjia\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m ):\n\u001b[0;32m---> 93\u001b[0m     results \u001b[39m=\u001b[39m collection\u001b[39m.\u001b[39;49mquery(\n\u001b[1;32m     94\u001b[0m         query_texts\u001b[39m=\u001b[39;49m[query],  \u001b[39m# TODO: look into what multiple queries will do here.\u001b[39;49;00m\n\u001b[1;32m     95\u001b[0m         n_results\u001b[39m=\u001b[39;49mn_results,\n\u001b[1;32m     96\u001b[0m         where\u001b[39m=\u001b[39;49m{embed_feature: {\u001b[39m\"\u001b[39;49m\u001b[39m$ne\u001b[39;49m\u001b[39m\"\u001b[39;49m: query}},  \u001b[39m# exact match is train/val contamination\u001b[39;49;00m\n\u001b[1;32m     97\u001b[0m         \u001b[39m# where={\u001b[39;49;00m\n\u001b[1;32m     98\u001b[0m         \u001b[39m#     \"$and\": [\u001b[39;49;00m\n\u001b[1;32m     99\u001b[0m         \u001b[39m#         {embed_feature: {\"$ne\": query}},\u001b[39;49;00m\n\u001b[1;32m    100\u001b[0m         \u001b[39m#         {\"db_id\": {\"$ne\": db_id}},\u001b[39;49;00m\n\u001b[1;32m    101\u001b[0m         \u001b[39m#     ]\u001b[39;49;00m\n\u001b[1;32m    102\u001b[0m         \u001b[39m# }\u001b[39;49;00m\n\u001b[1;32m    103\u001b[0m         \u001b[39m# TODO: test this:\u001b[39;49;00m\n\u001b[1;32m    104\u001b[0m         \u001b[39m# where_document={\"$ne\": query},  # exact match is train/val contamination\u001b[39;49;00m\n\u001b[1;32m    105\u001b[0m     )\n\u001b[1;32m    106\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/chromadb/api/models/Collection.py:220\u001b[0m, in \u001b[0;36mCollection.query\u001b[0;34m(self, query_embeddings, query_texts, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m where_document \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     where_document \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 220\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_query(\n\u001b[1;32m    221\u001b[0m     collection_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mid,\n\u001b[1;32m    222\u001b[0m     query_embeddings\u001b[39m=\u001b[39;49mquery_embeddings,\n\u001b[1;32m    223\u001b[0m     n_results\u001b[39m=\u001b[39;49mn_results,\n\u001b[1;32m    224\u001b[0m     where\u001b[39m=\u001b[39;49mwhere,\n\u001b[1;32m    225\u001b[0m     where_document\u001b[39m=\u001b[39;49mwhere_document,\n\u001b[1;32m    226\u001b[0m     include\u001b[39m=\u001b[39;49minclude,\n\u001b[1;32m    227\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/chromadb/api/segment.py:475\u001b[0m, in \u001b[0;36mSegmentAPI._query\u001b[0;34m(self, collection_id, query_embeddings, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    472\u001b[0m metadata_reader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_manager\u001b[39m.\u001b[39mget_segment(collection_id, MetadataReader)\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m where \u001b[39mor\u001b[39;00m where_document:\n\u001b[0;32m--> 475\u001b[0m     records \u001b[39m=\u001b[39m metadata_reader\u001b[39m.\u001b[39;49mget_metadata(\n\u001b[1;32m    476\u001b[0m         where\u001b[39m=\u001b[39;49mwhere, where_document\u001b[39m=\u001b[39;49mwhere_document\n\u001b[1;32m    477\u001b[0m     )\n\u001b[1;32m    478\u001b[0m     allowed_ids \u001b[39m=\u001b[39m [r[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m records]\n\u001b[1;32m    480\u001b[0m query \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mVectorQuery(\n\u001b[1;32m    481\u001b[0m     vectors\u001b[39m=\u001b[39mquery_embeddings,\n\u001b[1;32m    482\u001b[0m     k\u001b[39m=\u001b[39mn_results,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m     options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    486\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/chromadb/segment/impl/metadata/sqlite.py:148\u001b[0m, in \u001b[0;36mSqliteMetadataSegment.get_metadata\u001b[0;34m(self, where, where_document, ids, limit, offset)\u001b[0m\n\u001b[1;32m    146\u001b[0m offset \u001b[39m=\u001b[39m offset \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    147\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_db\u001b[39m.\u001b[39mtx() \u001b[39mas\u001b[39;00m cur:\n\u001b[0;32m--> 148\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(islice(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_records(cur, q), offset, offset \u001b[39m+\u001b[39;49m limit))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/chromadb/segment/impl/metadata/sqlite.py:163\u001b[0m, in \u001b[0;36mSqliteMetadataSegment._records\u001b[0;34m(self, cur, q)\u001b[0m\n\u001b[1;32m    160\u001b[0m group_iterator \u001b[39m=\u001b[39m groupby(cur_iterator, \u001b[39mlambda\u001b[39;00m r: \u001b[39mint\u001b[39m(r[\u001b[39m0\u001b[39m]))\n\u001b[1;32m    162\u001b[0m \u001b[39mfor\u001b[39;00m _, group \u001b[39min\u001b[39;00m group_iterator:\n\u001b[0;32m--> 163\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_record(\u001b[39mlist\u001b[39;49m(group))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/chromadb/segment/impl/metadata/sqlite.py:160\u001b[0m, in \u001b[0;36mSqliteMetadataSegment._records.<locals>.<lambda>\u001b[0;34m(r)\u001b[0m\n\u001b[1;32m    157\u001b[0m cur\u001b[39m.\u001b[39mexecute(sql, params)\n\u001b[1;32m    159\u001b[0m cur_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(cur\u001b[39m.\u001b[39mfetchone, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 160\u001b[0m group_iterator \u001b[39m=\u001b[39m groupby(cur_iterator, \u001b[39mlambda\u001b[39;00m r: \u001b[39mint\u001b[39;49m(r[\u001b[39m0\u001b[39;49m]))\n\u001b[1;32m    162\u001b[0m \u001b[39mfor\u001b[39;00m _, group \u001b[39min\u001b[39;00m group_iterator:\n\u001b[1;32m    163\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_record(\u001b[39mlist\u001b[39m(group))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embedding_feature = \"question\"\n",
    "dataset_parameters = {\n",
    "    \"dataset_name\": \"gsm8k\",\n",
    "      \"config_name\": \"main\"\n",
    "      }\n",
    "\n",
    "knowledge_base = generate_knowledge_base_from_hf_dataset(\n",
    "    dataset_parameters, embedding_feature, openai_ef\n",
    ")\n",
    "\n",
    "\n",
    "def format_math_example(example):\n",
    "    inference_prompt = f\"\"\"### Problem:\n",
    "{example[\"question\"]}\n",
    "\n",
    "### Answer:\"\"\"\n",
    "    full_prompt = f\"{inference_prompt}\\n{example['answer']}\"\n",
    "    return full_prompt, inference_prompt\n",
    "math_prompt = \"Solve the following math problem thinking step-by-step:\"\n",
    "\n",
    "augment_dataset_with_prompts(\n",
    "    dataset_parameters, knowledge_base, embedding_feature, format_math_example, math_prompt, n_examples=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embd_fn <chromadb.utils.embedding_functions.OpenAIEmbeddingFunction object at 0x7fd7eea70340>\n",
      "Collection.count is:  197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/sam/.cache/huggingface/datasets/beniben0___parquet/beniben0--small-chat-dataset-8a9c9071de6bce6e/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 1/1 [00:00<00:00, 434.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 197\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 23.52ba/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_feature = \"text\"\n",
    "dataset_parameters = {\n",
    "    \"dataset_name\": \"beniben0/small-chat-dataset\", \n",
    "    # \"config_name\": \"main\"\n",
    "    }\n",
    "\n",
    "knowledge_base = generate_knowledge_base_from_hf_dataset(\n",
    "    dataset_parameters, embedding_feature, openai_ef\n",
    ")\n",
    "\n",
    "\n",
    "def format_chat_example(example):\n",
    "    inference_prompt = f\"\"\"### Chat:\"\"\"\n",
    "    full_prompt = f\"{inference_prompt}\\n{example['text']}\"\n",
    "    return full_prompt, inference_prompt\n",
    "\n",
    "\n",
    "chat_prompt = \"Generate the following:\"\n",
    "\n",
    "augment_dataset_with_prompts(\n",
    "    dataset_parameters, knowledge_base, embedding_feature, format_chat_example, chat_prompt, n_examples=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
